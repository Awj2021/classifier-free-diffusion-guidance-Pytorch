{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from unet import Unet\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from diffusion import GaussianDiffusion\n",
    "from torchvision.utils import save_image,make_grid\n",
    "from utils import get_named_beta_schedule\n",
    "from embedding import ConditionalEmbedding\n",
    "from Scheduler import GradualWarmupScheduler\n",
    "from dataloader_cifar import load_data, transback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='test for diffusion model')\n",
    "parser.add_argument('--batchsize',type=int,default=128,help='batch size for training Unet model')\n",
    "parser.add_argument('--numworkers',type=int,default=4,help='num workers for training Unet model')\n",
    "parser.add_argument('--inch',type=int,default=3,help='input channels for Unet model')\n",
    "parser.add_argument('--modch',type=int,default=64,help='model channels for Unet model')\n",
    "parser.add_argument('--T',type=int,default=1000,help='timesteps for Unet model')\n",
    "parser.add_argument('--outch',type=int,default=3,help='output channels for Unet model')\n",
    "parser.add_argument('--chmul',type=list,default=[1,2,4,8],help='architecture parameters training Unet model')\n",
    "parser.add_argument('--numres',type=int,default=2,help='number of resblocks for each block in Unet model')\n",
    "parser.add_argument('--cdim',type=int,default=10,help='dimension of conditional embedding')\n",
    "parser.add_argument('--useconv',type=bool,default=True,help='whether use convlution in downsample')\n",
    "parser.add_argument('--droprate',type=float,default=0,help='dropout rate for model')\n",
    "parser.add_argument('--numheads',type=int,default=1,help='number of attention heads')\n",
    "parser.add_argument('--dtype',default=torch.float32)\n",
    "parser.add_argument('--lr',type=float,default=1e-4,help='learning rate')\n",
    "parser.add_argument('--w',type=float,default=1.8,help='hyperparameters for classifier-free guidance strength')\n",
    "parser.add_argument('--v',type=float,default=0.3,help='hyperparameters for the variance of posterior distribution')\n",
    "parser.add_argument('--epoch',type=int,default=20,help='epochs for training')\n",
    "parser.add_argument('--device',default=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),help='devices for training Unet model')\n",
    "parser.add_argument('--multiplier',type=float,default=2.5,help='multiplier for warmup')\n",
    "parser.add_argument('--threshold',type=float,default=0.1,help='threshold for classifier-free guidance')\n",
    "parser.add_argument('--moddir',type=str,default='model',help='model addresses')\n",
    "parser.add_argument('--samdir',type=str,default='sample',help='sample addresses')\n",
    "params = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = load_data(params)\n",
    "net = Unet(in_ch = params.inch,\n",
    "            mod_ch = params.modch,\n",
    "            out_ch = params.outch,\n",
    "            ch_mul = params.chmul,\n",
    "            num_res_blocks = params.numres,\n",
    "            cdim = params.cdim,\n",
    "            use_conv=params.useconv,\n",
    "            droprate = params.droprate,\n",
    "            num_heads = params.numheads,\n",
    "            dtype=params.dtype)\n",
    "betas = get_named_beta_schedule(num_diffusion_timesteps = params.T)\n",
    "optimizer = torch.optim.AdamW(net.parameters(),\n",
    "                            lr = params.lr,\n",
    "                            weight_decay = 1e-4)\n",
    "cosineScheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer = optimizer,\n",
    "                            T_max = params.epoch,\n",
    "                            eta_min = 0,\n",
    "                            last_epoch = -1)\n",
    "warmUpScheduler = GradualWarmupScheduler(optimizer = optimizer,\n",
    "                            multiplier = params.multiplier,\n",
    "                            warm_epoch = params.epoch // 10,\n",
    "                            after_scheduler = cosineScheduler)\n",
    "diffusion = GaussianDiffusion(dtype = params.dtype,\n",
    "                            model = net,\n",
    "                            betas = betas,\n",
    "                            w = params.w,\n",
    "                            v = params.v,\n",
    "                            device = params.device)\n",
    "cemblayer = ConditionalEmbedding(10, params.cdim, params.cdim).to(params.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc = 1\n",
    "with tqdm(dataloader, dynamic_ncols=True) as tqdmDataLoader:\n",
    "    for img, lab in tqdmDataLoader:\n",
    "        b = img.shape[0]\n",
    "        optimizer.zero_grad()\n",
    "        x_0 = img.to(params.device)\n",
    "        lab = lab.to(params.device)\n",
    "        cemb = cemblayer(lab)\n",
    "        cemb[np.where(np.random.rand(b)<params.threshold)] = 0\n",
    "        loss = diffusion.trainloss(x_0,{'cemb':cemb}) / (b**2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tqdmDataLoader.set_postfix(ordered_dict={\n",
    "            \"epoch\": epc,\n",
    "            \"loss: \": loss.item(),\n",
    "            \"img shape: \": x_0.shape,\n",
    "            \"LR\": optimizer.state_dict()['param_groups'][0][\"lr\"]\n",
    "        })\n",
    "warmUpScheduler.step()\n",
    "diffusion.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = torch.randint(low = 0, high = 10, size = (params.batchsize,), device=params.device)\n",
    "cemb = cemblayer(lab)\n",
    "genshape = (params.batchsize, 3, 32, 32)\n",
    "generated = diffusion.sample(genshape,{'cemb':cemb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = transback(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = make_grid(img, params.batchsize // 8, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_image(image, os.path.join(params.samdir, f'generated_{epc}_pict.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "770a45e8a44fe5b3f4478766980ae54cd65c1d2471607114cdbeec5f896e01da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
